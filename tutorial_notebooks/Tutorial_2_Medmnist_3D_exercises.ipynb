{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee73e205-d273-4b6c-878a-5ea958bfe267",
   "metadata": {
    "id": "ee73e205-d273-4b6c-878a-5ea958bfe267"
   },
   "source": [
    "# Federated Learning with SynapseMNIST3D Dataset\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/intel/fl-tutorial/blob/gh-pages/tutorial_notebooks/Tutorial_2_Medmnist_3D_exercises.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aebb0bc",
   "metadata": {},
   "source": [
    "### Dependencies and Packages\n",
    "Let's get these out of the way first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fafe9e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c6fafe9e",
    "outputId": "5e3fee4b-6bf6-4e0f-cca0-63f0826aaaaf"
   },
   "outputs": [],
   "source": [
    "!python -m pip install -U pip\n",
    "!python -m pip install tqdm torch torchvision medmnist acsconv matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c923a6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c9c923a6",
    "outputId": "e8641589-6afe-40b8-fe6d-0dcd42828534",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# To access example workspaces and director/envoy scripts\n",
    "!rm -rf openfl\n",
    "!git clone -b miccai_fl_tutorial https://github.com/intel/openfl.git\n",
    "!cd openfl && python -m pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f43b8fb",
   "metadata": {
    "id": "5f43b8fb"
   },
   "source": [
    "### Hacks\n",
    "\n",
    "A few duct-tape fixes to allow us to 1-click execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2698f1da-fa69-4543-bb15-c7c0dcb776b9",
   "metadata": {
    "id": "2698f1da-fa69-4543-bb15-c7c0dcb776b9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "# Better CPU Utilization\n",
    "os.environ['OMP_NUM_THREADS'] = str(int(os.cpu_count() // 2))\n",
    "\n",
    "# Logging fix for Google Colab\n",
    "log = logging.getLogger()\n",
    "log.setLevel(logging.INFO)\n",
    "\n",
    "# Switch to the workspace directory\n",
    "tutorial_dir = os.path.abspath(\n",
    "    'openfl/openfl-tutorials/interactive_api/PyTorch_MedMNIST_3D')\n",
    "os.chdir(tutorial_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f3623e",
   "metadata": {
    "id": "33f3623e"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca564a9a-8473-4207-aa41-c80111021e48",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ca564a9a-8473-4207-aa41-c80111021e48",
    "outputId": "f67adfb4-4be6-482b-b355-20816ea002e8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import medmnist\n",
    "\n",
    "print('PyTorch', torch.__version__)\n",
    "print('MedMNIST', medmnist.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b13b64",
   "metadata": {
    "id": "80b13b64"
   },
   "source": [
    "### Familiarize yourself with the Dataset\n",
    "\n",
    "MedMNIST is a large-scale MNIST-like collection of standardized biomedical images, including 12 datasets for 2D and 6 datasets for 3D. MedMNIST is designed to perform classification on lightweight 2D and 3D images with various data scales (from 100 to 100,000) and diverse tasks (binary/multi-class, ordinal regression and multi-label).\n",
    "\n",
    "![Datasets in MedMNIST](https://raw.githubusercontent.com/MedMNIST/MedMNIST/main/assets/medmnistv2.jpg)\n",
    "\n",
    "Source: https://github.com/MedMNIST/MedMNIST\n",
    "\n",
    "Jiancheng Yang, Rui Shi, Donglai Wei, Zequan Liu, Lin Zhao, Bilian Ke, Hanspeter Pfister, Bingbing Ni. \"MedMNIST v2: A Large-Scale Lightweight Benchmark for 2D and 3D Biomedical Image Classification\". arXiv preprint arXiv:2110.14795, 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09e752f",
   "metadata": {
    "id": "e09e752f"
   },
   "source": [
    "### Dataset Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb169b9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5bb169b9",
    "outputId": "87316233-9a2e-47ac-d7e1-eec64a52feac"
   },
   "outputs": [],
   "source": [
    "# Train/test options\n",
    "NUM_EPOCHS = 3\n",
    "BATCH_SIZE = 16\n",
    "DEVICE = 'cpu'\n",
    "\n",
    "# Dataset\n",
    "DATASET_NAME = 'synapsemnist3d'\n",
    "DATASET_PATH = './data'\n",
    "ds_info = medmnist.INFO[DATASET_NAME]\n",
    "pprint(ds_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41e7859",
   "metadata": {
    "id": "c41e7859"
   },
   "source": [
    "### Familiarize with the Dataset\n",
    "\n",
    "Let's use some plotting tools here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1178e597",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456,
     "referenced_widgets": [
      "c8ff01957047400fa84f62b84035a1be",
      "98d21bfd65b84efea7e3230a56a649a1",
      "c41b087ab1854ff585174c031422f6ca",
      "92ba5282ebab4b94bd69fe25afd667d6",
      "afef3d94eb3f4119b0cccf1de42a09de",
      "1fc6b98994cb454fa65021f97359f53f",
      "d9ee140346a8415b87647ab37a263fe2",
      "3937763c9cad4f10b116cd93f80dbe09",
      "0fc8a27567a04d4baad52c0320d849ab",
      "868c8d7419b844d6875421bb75708bf0",
      "79b4367f01844bc1846b318bbc4e84b5"
     ]
    },
    "id": "1178e597",
    "outputId": "0e7eb7ab-cdea-4364-da60-6d7c504c9e79"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from envoy.medmnist_shard_descriptor import MedMNISTShardDescriptor\n",
    "\n",
    "# Download raw numpy dataset\n",
    "sd = MedMNISTShardDescriptor(datapath=DATASET_PATH, dataname=DATASET_NAME)\n",
    "(x_train, y_train), (x_test, y_test) = sd.load_data()\n",
    "\n",
    "# Visualize a sample\n",
    "sample_id = 42\n",
    "label2str = list(ds_info['label'].values())\n",
    "volume = x_train[sample_id]\n",
    "label = label2str[np.squeeze(y_train[sample_id])]\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "cmap = plt.get_cmap(\"gray\")\n",
    "norm = plt.Normalize(volume.min(), volume.max())\n",
    "ax.voxels(volume, facecolors=cmap(norm(volume)))\n",
    "plt.title(label)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba176624",
   "metadata": {
    "id": "ba176624"
   },
   "source": [
    "### Define Dataset/Dataloader Classes\n",
    "\n",
    "We'll create a simple PyTorch-style iterator dataset that returns single `numpy` element as a `torch.Tensor`. The class used for this would be `torch.utils.data.Dataset`\n",
    "\n",
    "We will then wrap this dataset object with a Dataloader class, that batches and shuffles the elements. Class: `torch.utils.data.DataLoader`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1637381d-84d0-4132-92c3-bf1a1e9c7f7a",
   "metadata": {
    "id": "1637381d-84d0-4132-92c3-bf1a1e9c7f7a"
   },
   "source": [
    "### Model Definition (3D CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vSRyhzr6JpTd",
   "metadata": {
    "id": "vSRyhzr6JpTd"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(in_channels, 16, kernel_size=3),\n",
    "                                    nn.BatchNorm2d(16), nn.ReLU())\n",
    "\n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(16, 16, kernel_size=3),\n",
    "                                    nn.BatchNorm2d(16), nn.ReLU(),\n",
    "                                    nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.layer3 = nn.Sequential(nn.Conv2d(16, 64, kernel_size=3),\n",
    "                                    nn.BatchNorm2d(64), nn.ReLU())\n",
    "\n",
    "        self.layer4 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=3),\n",
    "                                    nn.BatchNorm2d(64), nn.ReLU())\n",
    "\n",
    "        self.layer5 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "                                    nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                                    nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.fc = nn.Sequential(nn.Linear(64 * 4 * 4 * 4, 128), \n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(0.5),\n",
    "                                nn.Linear(128, num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2e26a5-9f4e-4011-a999-e428246aa8c1",
   "metadata": {
    "id": "cd2e26a5-9f4e-4011-a999-e428246aa8c1"
   },
   "source": [
    "# Go Federated\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d105a0-04c4-4c26-81c7-a350e14393c2",
   "metadata": {
    "id": "b0d105a0-04c4-4c26-81c7-a350e14393c2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import yaml\n",
    "from typing import Dict, List, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10243b0d",
   "metadata": {
    "id": "10243b0d"
   },
   "source": [
    "### Configure `Director`\n",
    "\n",
    "This is the entity that orchestrates the tasks and aggregation of models from participants. Below cells are to configure the `yaml` and start the `Director` service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e736d33f-5df2-4a2f-8210-f1feba9fd367",
   "metadata": {
    "id": "e736d33f-5df2-4a2f-8210-f1feba9fd367"
   },
   "outputs": [],
   "source": [
    "# Should be the same as defined in `director_config.yaml`\n",
    "director_node_fqdn = 'localhost'\n",
    "director_port = 50051\n",
    "\n",
    "director_workspace_path = os.path.join(tutorial_dir, 'director')\n",
    "director_config_file = os.path.join(director_workspace_path,'director_config.yaml')\n",
    "director_logfile = os.path.join(director_workspace_path, 'director.log')\n",
    "\n",
    "# Start director\n",
    "os.system(f'cd {director_workspace_path};'\n",
    "          f'fx director start --disable-tls -c {director_config_file} '\n",
    "          f'>{director_logfile} &')\n",
    "!sleep 5 && tail -n5 $director_logfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223f0037-c87e-440d-b8df-8fe9211c34dc",
   "metadata": {
    "id": "223f0037-c87e-440d-b8df-8fe9211c34dc",
    "tags": []
   },
   "source": [
    "### Configure `Envoys`\n",
    "\n",
    "`Envoy`, for sake of simplicity, can be thought of as collaborators. Technically, `Envoy` defines the dataloading interface for each participant and runs python code (called a `task`) that it receives via this notebook.\n",
    "\n",
    "We create as many config files as number of participants that we intend to simulate here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e65a39-15f7-4cca-90bb-a2970b7be9f0",
   "metadata": {
    "id": "c0e65a39-15f7-4cca-90bb-a2970b7be9f0"
   },
   "outputs": [],
   "source": [
    "def generate_envoy_configs(\n",
    "        config: dict,\n",
    "        n_cols: int,\n",
    "        datapath: str,\n",
    "        dataname: str,\n",
    "        save_path: str) -> list:\n",
    "    \n",
    "    config_paths = list()\n",
    "    for i in range(1, n_cols+1):\n",
    "        path = os.path.abspath(os.path.join(save_path, f'{i}_envoy_config.yaml'))\n",
    "        config['shard_descriptor']['params']['datapath'] = datapath\n",
    "        config['shard_descriptor']['params']['dataname'] = dataname    \n",
    "        config['shard_descriptor']['params']['rank_worldsize'] = f'{i},{n_cols}'\n",
    "        with open(path, 'w') as f:\n",
    "            yaml.safe_dump(config, f)\n",
    "        config_paths.append(path)\n",
    "    return config_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab32d5c",
   "metadata": {},
   "source": [
    "### Generate configs and start `Envoys`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90109c5b-c785-4af7-ace9-dcd913018dca",
   "metadata": {
    "id": "90109c5b-c785-4af7-ace9-dcd913018dca"
   },
   "outputs": [],
   "source": [
    "# Read the original envoy config file content\n",
    "original_config_path = os.path.join(tutorial_dir, 'envoy', 'envoy_config.yaml')\n",
    "with open(original_config_path, 'r') as f:\n",
    "    original_config = yaml.safe_load(f)\n",
    "\n",
    "# Generate configs for as many envoys\n",
    "config_paths = generate_envoy_configs(original_config,\n",
    "                                      n_cols=2,\n",
    "                                      datapath=DATASET_PATH,\n",
    "                                      dataname=DATASET_NAME,\n",
    "                                      save_path=os.path.dirname(original_config_path))\n",
    "# Start envoys in a loop\n",
    "cwd = os.getcwd()\n",
    "for i, path in enumerate(config_paths):\n",
    "    print(f'Starting Envoy {i+1}')\n",
    "    os.chdir(os.path.dirname(path))\n",
    "\n",
    "    # Wait until envoy loads dataset\n",
    "    os.system(f'fx envoy start -n env_{i+1} --disable-tls '\n",
    "                f'--envoy-config-path {path} -dh {director_node_fqdn} -dp {director_port} '\n",
    "                f'>env_{i+1}.log 2>&1 &')\n",
    "    !grep -q \"MedMNIST data was loaded\" <( tail -f env_{i+1}.log )\n",
    "    \n",
    "    os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6216f14c-78d8-444c-9144-ee8316d1487b",
   "metadata": {
    "id": "6216f14c-78d8-444c-9144-ee8316d1487b"
   },
   "source": [
    "### Connect this Notebook to the Infrastructure\n",
    "\n",
    "This is where you take the seat of a Data Scientist, who bears control over the `model`, `train()`, `validate()` and other logic that `Director` and `Envoy` help you execute across participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d3b764-cb86-4eec-ba8e-df119da7a27f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b9d3b764-cb86-4eec-ba8e-df119da7a27f",
    "outputId": "d615ffc4-e178-4fe1-9d31-436a0f721975"
   },
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.federation import Federation\n",
    "\n",
    "# Create a federation\n",
    "federation = None\n",
    "\n",
    "# Wait till all envoys publish their shard registry.\n",
    "pprint(federation.get_shard_registry())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6401026-795f-491e-90cb-dd59b451df5f",
   "metadata": {
    "id": "c6401026-795f-491e-90cb-dd59b451df5f"
   },
   "source": [
    "### Ingredients of a Federated Learning Experiment in OpenFL\n",
    "\n",
    "* `DataInterface`: This class defines the dataloading primitives for OpenFL. We'll reuse some of our previous logic.\n",
    "* `ModelInterface`: Registers model graph and optimizer; serializes them and sends them to collaborator nodes.\n",
    "* `TaskInterface`: Registers the python methods that constitute each task like `training`, `validation` etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f9d6e8-d020-4ceb-89d0-14113e0f8b9e",
   "metadata": {
    "id": "13f9d6e8-d020-4ceb-89d0-14113e0f8b9e"
   },
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.experiment import DataInterface\n",
    "\n",
    "# A fix to access the following module\n",
    "os.chdir(os.path.join(tutorial_dir, 'workspace'))\n",
    "from wspace_utils.utils import Transform3D\n",
    "\n",
    "class TransformDataset(Dataset):\n",
    "    \"\"\"Applies transforms to each element of the Dataset\"\"\"\n",
    "\n",
    "    def __init__(self, dataset, transform=None, target_transform=None):\n",
    "        \"\"\"Initializes Dataset\"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns length of the dataset\"\"\"\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Returns img, label by index, with transforms if any\"\"\"\n",
    "        img, label = self.dataset[index]\n",
    "        img = np.stack([img/255.], axis=0)\n",
    "        \n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "# Transforms\n",
    "shape_transform = False\n",
    "train_transform = Transform3D(mul='random') if shape_transform else Transform3D()\n",
    "eval_transform = Transform3D(mul='0.5') if shape_transform else Transform3D()\n",
    "\n",
    "class MedMnistFedDataset(DataInterface):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    @property\n",
    "    def shard_descriptor(self):\n",
    "        return self._shard_descriptor\n",
    "\n",
    "    @shard_descriptor.setter\n",
    "    def shard_descriptor(self, shard_descriptor):\n",
    "        \"\"\"\n",
    "        Describe per-collaborator procedures or sharding.\n",
    "\n",
    "        This method will be called during a collaborator initialization.\n",
    "        Local shard_descriptor  will be set by Envoy.\n",
    "        \"\"\"\n",
    "        self._shard_descriptor = shard_descriptor\n",
    "\n",
    "        self.train_set = TransformDataset(\n",
    "            self._shard_descriptor.get_dataset('train'),\n",
    "            transform=train_transform)\n",
    "\n",
    "        self.valid_set = TransformDataset(\n",
    "            self._shard_descriptor.get_dataset('val'),\n",
    "            transform=eval_transform)\n",
    "\n",
    "    def get_train_loader(self, **kwargs):\n",
    "        \"\"\"Output of this method will be provided to tasks with optimizer in contract\"\"\"\n",
    "        return DataLoader(self.train_set,\n",
    "                          num_workers=8,\n",
    "                          batch_size=self.kwargs['train_bs'],\n",
    "                          shuffle=True)\n",
    "\n",
    "    def get_valid_loader(self, **kwargs):\n",
    "        \"\"\"Output of this method will be provided to tasks without optimizer in contract\"\"\"\n",
    "        return DataLoader(self.valid_set,\n",
    "                          num_workers=8,\n",
    "                          batch_size=self.kwargs['valid_bs'])\n",
    "\n",
    "    def get_train_data_size(self):\n",
    "        \"\"\"Information for aggregation\"\"\"\n",
    "        return len(self.train_set)\n",
    "\n",
    "    def get_valid_data_size(self):\n",
    "        \"\"\"Information for aggregation\"\"\"\n",
    "        return len(self.valid_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccccaa67-6dfb-437f-b201-46b2a2561730",
   "metadata": {
    "id": "ccccaa67-6dfb-437f-b201-46b2a2561730"
   },
   "outputs": [],
   "source": [
    "fed_dataset = MedMnistFedDataset(train_bs=BATCH_SIZE, valid_bs=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6233e1ed-a2f2-456f-9417-f35a2c27b236",
   "metadata": {
    "id": "6233e1ed-a2f2-456f-9417-f35a2c27b236"
   },
   "source": [
    "### `ModelInterface`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885a8530-6248-4060-a30a-45cdc79bc41a",
   "metadata": {
    "id": "885a8530-6248-4060-a30a-45cdc79bc41a"
   },
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.experiment import ModelInterface\n",
    "\n",
    "from acsconv.converters import Conv3dConverter\n",
    "from wspace_utils.utils import model_to_syncbn\n",
    "\n",
    "def get_3d_cnn():\n",
    "  ## Fill: Instantiate a model\n",
    "  model = None\n",
    "\n",
    "  ## Fill: Convert model to 3D using Conv3dConverter\n",
    "  model = None\n",
    "\n",
    "  ## Fill: Convert all BatchNorm layers to SyncBN layers\n",
    "  model = None\n",
    "  return model\n",
    "\n",
    "model = get_3d_cnn()\n",
    "optimizer = None  ## Fill: Instantiate an `Adam` Optimizer\n",
    "criterion = None  ## Fill: Instantiate a CrossEntropyLoss function\n",
    "\n",
    "framework_adapter = 'openfl.plugins.frameworks_adapters.pytorch_adapter.FrameworkAdapterPlugin'\n",
    "MI = ModelInterface(model=model.model,\n",
    "                    optimizer=optimizer,\n",
    "                    framework_plugin=framework_adapter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1962b396",
   "metadata": {
    "id": "1962b396"
   },
   "source": [
    "### `TaskInterface`\n",
    "We register our tasks with a `TaskInterface` class.\n",
    "OpenFL decides which model is the best based on an *increasing* metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e101689-8a63-4562-98ff-09443b1ab9f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7e101689-8a63-4562-98ff-09443b1ab9f2",
    "outputId": "3b659598-4c41-4534-e7a0-5433f03b1eb6"
   },
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.experiment import TaskInterface\n",
    "\n",
    "# Task interface currently supports only standalone functions.\n",
    "TI = TaskInterface()\n",
    "extra_args = {'criterion': criterion}\n",
    "\n",
    "# Train task\n",
    "@TI.add_kwargs(**extra_args)\n",
    "@TI.register_fl_task(model='model', data_loader='data_loader', device='device', optimizer='optimizer')\n",
    "def train(model: nn.Module, \n",
    "          data_loader: torch.utils.data.DataLoader,\n",
    "          device: str,\n",
    "          optimizer: torch.optim.Optimizer, \n",
    "          criterion: nn.Module) -> dict:\n",
    "    \"\"\"Trains `model` for 1 epoch on `train_loader`\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): PyTorch Model.\n",
    "        dataloader (torch.utils.data.DataLoader): Training Dataloader.\n",
    "        optimizer (torch.optim.Optimizer): Optimizer instance.\n",
    "        criterion (nn.Module): Loss function instance.\n",
    "\n",
    "    Returns:\n",
    "        dict: `acc` and `loss` metrics over the dataloader\n",
    "    \"\"\"\n",
    "    ## Set the model to training mode\n",
    "    \n",
    "\n",
    "    ## Initialize counters for accuracy/loss\n",
    "    losses = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    ## Create a `for` loop that iterates over the dataloader\n",
    "    for x, y in tqdm(data_loader, desc='training'):\n",
    "        ## Push `x` and `y` tensors to the device\n",
    "        \n",
    "        ## Squeeze and Convert `y` to a `long` tensor\n",
    "\n",
    "        ## Clear optimizer gradients\n",
    "        \n",
    "        ## Forward pass `x` through the model to get `preds`\n",
    "        preds = None\n",
    "        \n",
    "        ## Calculate `loss` using the criterion\n",
    "        loss = None\n",
    "\n",
    "        ## Backpropagate `loss` to compute gradients\n",
    "        \n",
    "        ## Apply gradients with step\n",
    "        \n",
    "        ## Record metrics\n",
    "        losses.append(loss.item())\n",
    "        correct += torch.sum(preds.max(1)[1] == y).item()\n",
    "        total += y.size(0)\n",
    "\n",
    "    #############################################################\n",
    "    return {\n",
    "        'train_acc': np.round(correct/total, 3),\n",
    "        'train_loss': np.round(np.mean(losses), 3),\n",
    "    }\n",
    "\n",
    "@TI.add_kwargs(**extra_args)\n",
    "@TI.register_fl_task(model='model', data_loader='data_loader', device='device')\n",
    "def validate(model: nn.Module, \n",
    "             data_loader: torch.utils.data.DataLoader,\n",
    "             device: str,\n",
    "             criterion: nn.Module) -> dict:\n",
    "    \"\"\"Computes `acc` and `loss` of the `model` on `val_loader`\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): PyTorch Model.\n",
    "        data_loader (torch.utils.data.DataLoader): Validation Dataloader.\n",
    "        device (str): 'cpu' or 'cuda'\n",
    "        criterion (nn.Module): Loss function instance.\n",
    "\n",
    "    Returns:\n",
    "        dict: `acc` and `loss` metrics over the dataloader\n",
    "    \"\"\"\n",
    "    ## Set the model to evaluation mode\n",
    "\n",
    "\n",
    "    ## Initialize counters for accuracy/loss\n",
    "    losses = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    ## Define a scope that disables gradient calculation\n",
    "    with torch.no_grad():\n",
    "        ## Create a `for` loop that iterates over the dataloader\n",
    "        for x, y in tqdm(data_loader, desc='validating'):\n",
    "            ## Push `x` and `y` tensors to the device\n",
    "            \n",
    "            ## Squeeze and Convert `y` to a `long` tensor\n",
    "            \n",
    "            ## Forward pass `x` through the model to get `preds`\n",
    "            preds = None\n",
    "            \n",
    "            ## Calculate `loss` using the criterion\n",
    "            loss = None\n",
    "            \n",
    "            ## Record metrics\n",
    "            losses.append(loss.item())\n",
    "            correct += torch.sum(preds.max(1)[1] == y).item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    #############################################################\n",
    "\n",
    "    return {\n",
    "        'val_acc': np.round(correct/total, 3),\n",
    "        'val_loss': np.round(np.mean(losses), 3),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a4623e-6559-4d4c-b199-f9afe16c0bbd",
   "metadata": {
    "id": "40a4623e-6559-4d4c-b199-f9afe16c0bbd",
    "tags": []
   },
   "source": [
    "### Run the Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb357a88-7098-45b2-85f4-71fe2f2e0f82",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fb357a88-7098-45b2-85f4-71fe2f2e0f82",
    "outputId": "80bbefa7-a826-47d4-a620-06d42e1b2cd3"
   },
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.experiment import FLExperiment\n",
    "\n",
    "## Create a unique FL Experiment under this infrastructure:{Notebook, Director, Envoy}\n",
    "fl_experiment = None\n",
    "fl_experiment.start(model_provider=MI,\n",
    "                    task_keeper=TI,\n",
    "                    data_loader=fed_dataset,\n",
    "                    rounds_to_train=3,\n",
    "                    device_assignment_policy='CUDA_PREFERRED')\n",
    "\n",
    "# This method streams logs from the director, and also saves logs in the tensorboard format (by default)\n",
    "fl_experiment.stream_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e365766-4ea6-40bc-96ae-a183274e8b8c",
   "metadata": {
    "id": "9e365766-4ea6-40bc-96ae-a183274e8b8c"
   },
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d793be-6c20-4a22-bad7-c082c1ee76ca",
   "metadata": {
    "id": "e5d793be-6c20-4a22-bad7-c082c1ee76ca"
   },
   "outputs": [],
   "source": [
    "# To stop all services run\n",
    "!pkill fx\n",
    "[os.remove(path) for path in config_paths]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "f43db3e1b37af6d897db69efad3b1c690ae8b3c11b26caaa91054cfebd4932bb"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0fc8a27567a04d4baad52c0320d849ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1fc6b98994cb454fa65021f97359f53f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3937763c9cad4f10b116cd93f80dbe09": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79b4367f01844bc1846b318bbc4e84b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "868c8d7419b844d6875421bb75708bf0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92ba5282ebab4b94bd69fe25afd667d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_868c8d7419b844d6875421bb75708bf0",
      "placeholder": "​",
      "style": "IPY_MODEL_79b4367f01844bc1846b318bbc4e84b5",
      "value": " 38034583/38034583 [00:35&lt;00:00, 3013484.65it/s]"
     }
    },
    "98d21bfd65b84efea7e3230a56a649a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1fc6b98994cb454fa65021f97359f53f",
      "placeholder": "​",
      "style": "IPY_MODEL_d9ee140346a8415b87647ab37a263fe2",
      "value": "100%"
     }
    },
    "afef3d94eb3f4119b0cccf1de42a09de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c41b087ab1854ff585174c031422f6ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3937763c9cad4f10b116cd93f80dbe09",
      "max": 38034583,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0fc8a27567a04d4baad52c0320d849ab",
      "value": 38034583
     }
    },
    "c8ff01957047400fa84f62b84035a1be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_98d21bfd65b84efea7e3230a56a649a1",
       "IPY_MODEL_c41b087ab1854ff585174c031422f6ca",
       "IPY_MODEL_92ba5282ebab4b94bd69fe25afd667d6"
      ],
      "layout": "IPY_MODEL_afef3d94eb3f4119b0cccf1de42a09de"
     }
    },
    "d9ee140346a8415b87647ab37a263fe2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
